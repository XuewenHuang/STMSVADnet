import cv2
import torch
import numpy as np


def log10(t):
    """
    Calculates the base-10 tensorboard_log of each element in t.
    @param t: The tensor from which to calculate the base-10 tensorboard_log.
    @return: A tensor with the base-10 tensorboard_log of each element in t.
    """
    numerator = torch.log(t)
    denominator = torch.log(torch.FloatTensor([10.])).cuda()
    return numerator / denominator


def psnr_error(gen_frames, gt_frames):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.
    @param gen_frames: A tensor of shape [batch_size, 3, height, width]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, 3, height, width]. The ground-truth frames for
                      each frame in gen_frames.
    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the
             batch.
    """
    shape = list(gen_frames.shape)
    num_pixels = (shape[1] * shape[2] * shape[3])
    gt_frames = (gt_frames + 1.0) / 2.0  # if the generate ouuput is sigmoid output, modify here.
    gen_frames = (gen_frames + 1.0) / 2.0
    square_diff = (gt_frames - gen_frames) ** 2
    batch_errors = 10 * log10(1. / ((1. / num_pixels) * torch.sum(square_diff, [1, 2, 3])))
    return batch_errors


def weights_init_normal(m):
    classname = m.__class__.__name__
    init_type = 'normal'
    if classname.find('Conv') != -1:
        if init_type == 'normal':
            torch.nn.init.normal_(m.weight.data, 0.0, 0.02)
        elif init_type == 'xavier':
            torch.nn.init.xavier_normal_(m.weight.data, gain=0.02)
        elif init_type == 'kaiming':
            torch.nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in', nonlinearity='relu')
        elif init_type == 'orthogonal':  # 正交初始化
            torch.nn.init.orthogonal_(m.weight.data, gain=0.02)
        else:
            raise NotImplementedError('initialization method [%s] is not implemented' % init_type)

    elif classname.find('BatchNorm2d') != -1:
        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
        torch.nn.init.constant_(m.bias.data, 0.0)


def patch_max_mse(diff_map_appe, patches=3, size=16, step=4, is_multi=False):
    assert size % step == 0

    b_size = diff_map_appe.shape[0]
    max_mean = np.zeros([b_size, patches])

    # sliding window
    for i in range(0, diff_map_appe.shape[-2] - size, step):
        for j in range(0, diff_map_appe.shape[-1] - size, step):

            curr_mean = np.mean(diff_map_appe[..., i:i + size, j:j + size], axis=(1, 2, 3))
            for b in range(b_size):
                for n in range(patches):
                    if curr_mean[b] > max_mean[b, n]:
                        max_mean[b, n + 1:] = max_mean[b, n:-1]
                        max_mean[b, n] = curr_mean[b]
                        break
    return max_mean[:, 0]  #


def multi_patch_max_mse(diff_map_appe):
    mse_32 = patch_max_mse(diff_map_appe, patches=3, size=32, step=8, is_multi=False)
    mse_64 = patch_max_mse(diff_map_appe, patches=3, size=64, step=16, is_multi=False)
    mse_128 = patch_max_mse(diff_map_appe, patches=3, size=128, step=32, is_multi=False)
    return mse_32, mse_64, mse_128


def psnr_v(mse):
    return 10 * np.log10(1 / mse)


def multi_future_frames_to_scores(input):
    output = cv2.GaussianBlur(input, (5, 0), 10)
    return output
